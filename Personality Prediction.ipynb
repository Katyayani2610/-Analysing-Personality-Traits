{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"c1984163-fffe-41aa-99a0-243673f1bf51","_uuid":"e1fd66d81a1166c3f8054857e1824c5de671bb09","trusted":true},"outputs":[],"source":["import re\n","import numpy as np\n","import collections\n","from collections import Counter\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from bokeh.io import output_file, show\n","from bokeh.plotting import figure\n","from bokeh.models import ColumnDataSource, HoverTool\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import Perceptron\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","df = pd.read_csv('../input/mbti_1.csv')\n","print(df.head(10))\n","print(\"*\"*40)\n","print(df.info())\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"fb2b5c26-42e1-4b04-8ef4-16999b6ab6f1","_uuid":"84dec5efb299b0d3fb4988a295e8c03087539f26"},"source":["We can thus see that there are no null inputs, which means there is no need for cleaning the data. \n","\n","The first idea that pops up is checking if the words per tweet of each person shows us some information. For that reason, we can create a new column as shown below.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"e8029602-1dc9-4a2a-b4e1-7072f81c565b","_uuid":"ffcbdf4d43d2017e187f58a69d58cde88f5206b2","trusted":true},"outputs":[],"source":["df['words_per_comment'] = df['posts'].apply(lambda x: len(x.split())/50)\n","print(df.head())"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f2a405e1-afa0-4dbb-9ee8-1164e1be07bb","_uuid":"d1a10157637263e2867e24564a19368ea371708a"},"source":["# **Exploratory data analysis**\n","\n","We may use it for one reason or for another, but one thing we can do is printing a violin plot. \n","\n","At the end I did not use it at all, but it is always nice to have the ability do some visual analysis for further investigations. "]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"29fc9dd1-39f2-49fa-8034-a887def80113","_uuid":"903c6696d37f517ec51d35309e902e46daf2d789","trusted":true},"outputs":[],"source":["plt.figure(figsize=(15,10))\n","sns.violinplot(x='type', y='words_per_comment', data=df, inner=None, color='lightgray')\n","sns.stripplot(x='type', y='words_per_comment', data=df, size=4, jitter=True)\n","plt.ylabel('Words per comment')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"08bbe211-a91c-45b3-9330-016dbecfca96","_uuid":"a72478621467a2a67d0f561a220e26af50e37ea2"},"source":["There's quite a lot of information there. \n","\n","Creating new columns showing the amount of questionmarks per comment, exclamations or other types will be useful later on, as we will see. This are the examples I came up with, but here is where creativity comes into play.\n","\n","We can also perform joint plots, pair plots and heat maps to explore relationship between data, just for fun."]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"a5365240-b4f1-45b9-801f-639155108f45","_uuid":"2a92888c4fae4668421f151609c47fde41764d22","trusted":true},"outputs":[],"source":["df['http_per_comment'] = df['posts'].apply(lambda x: x.count('http')/50)\n","df['music_per_comment'] = df['posts'].apply(lambda x: x.count('music')/50)\n","df['question_per_comment'] = df['posts'].apply(lambda x: x.count('?')/50)\n","df['img_per_comment'] = df['posts'].apply(lambda x: x.count('jpg')/50)\n","df['excl_per_comment'] = df['posts'].apply(lambda x: x.count('!')/50)\n","df['ellipsis_per_comment'] = df['posts'].apply(lambda x: x.count('...')/50)\n","\n","plt.figure(figsize=(15,10))\n","sns.jointplot(x='words_per_comment', y='ellipsis_per_comment', data=df, kind='kde')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a14470ad-642a-4640-a64b-c6184c426f32","_uuid":"edf176de9553085fdecbd60a477ed77aa6f7ceeb"},"source":["So it seems there's a large correlation between words per comment ant the ellipsis the user types per comment! Based on pearson correlation factor there is a note of of 69% correlation between ellipsis_per_comments and words_per_comment. \n","\n","<center><h3> 69% ~ words correlating with ellipsis</h3> </center>\n","\n","This is an interesting first step, and we are interested in taking a further look into the data as we are on a mission to discover if we can predict the personality types of users based on there social media comments with a little help from machine learning. :)"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa6ffe2f358f18a4347757907a8300239ca5f96"},"source":["### Exploratory Analysis Pt. 2\n","We are focusing on the correlation variables for  the different types of the personality types the Meyer Briggs outline in comparision to the words comments and ellipses per comment as well. Let's see which personality type will yield the highest correlation value. "]},{"cell_type":"code","execution_count":16,"metadata":{"_cell_guid":"7820e7c7-a4c8-4249-ae87-dae21a39608f","_uuid":"7b86180aa6b7409252aecb45ad065fd3faa49718","trusted":true},"outputs":[],"source":["i = df['type'].unique()\n","k = 0\n","for m in range(0,2):\n","    for n in range(0,6):\n","        df_2 = df[df['type'] == i[k]]\n","        sns.jointplot(x='words_per_comment', y='ellipsis_per_comment', data=df_2, kind=\"hex\")\n","        plt.title(i[k])\n","        k+=1\n"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"dcdb7444-2da6-4660-acfe-5a9321a3af35","_uuid":"831d063f8b916840403709f51736ad616aad99e8","trusted":true},"outputs":[],"source":["i = df['type'].unique()\n","k = 0\n","TypeArray = []\n","PearArray=[]\n","for m in range(0,2):\n","    for n in range(0,6):\n","        df_2 = df[df['type'] == i[k]]\n","        pearsoncoef1=np.corrcoef(x=df_2['words_per_comment'], y=df_2['ellipsis_per_comment'])\n","        pear=pearsoncoef1[1][0]\n","        print(pear)\n","        TypeArray.append(i[k])\n","        PearArray.append(pear)\n","        k+=1\n","\n","\n","TypeArray = [x for _,x in sorted(zip(PearArray,TypeArray))]\n","PearArray = sorted(PearArray, reverse=True)\n","print(PearArray)\n","print(TypeArray)\n","plt.scatter(TypeArray, PearArray)"]},{"cell_type":"markdown","metadata":{"_uuid":"835fb91ef4cfcd45d3b617771e4ea25a1727bbe8"},"source":["# Discussion\n","Highest correlation values to the ellispes and comments are as following for the top three:\n","* INFJ  - Intorversion Intuition Feeling Judging \n","* INTP \n","* ENFP \n","* "]},{"cell_type":"markdown","metadata":{"_cell_guid":"54495ba1-ad20-4149-a843-f927c40d0f56","_uuid":"32a81450ae9c91a8ff26106b8e05362543d74aff"},"source":["# **Data preprocessing**\n","\n","To get a further insight on our dataset, we can first create 4 new columns dividing the people by introversion/extroversion, intuition/sensing, and so on. \n","\n","When it comes to performing machine learning, trying to distinguish between two categories is much easier than distinguishing between 16 categories. We will check that later on. Dividing the data in 4 small groups will perhaps be more useful when it comes to accuracy."]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"324bae84-3068-4bb6-b0ec-11a76683ddd5","_uuid":"2a2c8c86d9f4cfe5bac1a34b23eb1bc71cbaacd6","trusted":true},"outputs":[],"source":["map1 = {\"I\": 0, \"E\": 1}\n","map2 = {\"N\": 0, \"S\": 1}\n","map3 = {\"T\": 0, \"F\": 1}\n","map4 = {\"J\": 0, \"P\": 1}\n","df['I-E'] = df['type'].astype(str).str[0]\n","df['I-E'] = df['I-E'].map(map1)\n","df['N-S'] = df['type'].astype(str).str[1]\n","df['N-S'] = df['N-S'].map(map2)\n","df['T-F'] = df['type'].astype(str).str[2]\n","df['T-F'] = df['T-F'].map(map3)\n","df['J-P'] = df['type'].astype(str).str[3]\n","df['J-P'] = df['J-P'].map(map4)\n","print(df.head(10))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6441ac53-9d10-4312-9191-0f0ecd440f2e","_uuid":"1488ee7975b272f31b284e6b7e6c8580042c150d"},"source":["# **Building machine learning algorithms**\n","\n","Let's do some machine learning now, first with the entire \"type\" column, with different models. Let's crank it out to the max!"]},{"cell_type":"code","execution_count":18,"metadata":{"_cell_guid":"0acd5e9e-22e6-4f4f-afe0-76e2a54507e2","_uuid":"8c0d4b61a57e057d26dc858c317bab32d9541580","trusted":true},"outputs":[],"source":["X = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1).values\n","y = df['type'].values\n","\n","print(y.shape)\n","print(X.shape)\n","\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size = 0.1, random_state=5)\n","\n","sgd = SGDClassifier(max_iter=5, tol=None)\n","sgd.fit(X_train, y_train)\n","Y_pred = sgd.predict(X_test)\n","sgd.score(X_train, y_train)\n","acc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\n","print(round(acc_sgd,2,), \"%\")"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"75aa73c4-8331-41c2-b310-2e7f423611c7","_uuid":"30168f35c770296823db30dfedad1146ee8042b7","trusted":true},"outputs":[],"source":["# Random Forest\n","random_forest = RandomForestClassifier(n_estimators=100)\n","random_forest.fit(X_train, y_train)\n","\n","Y_prediction = random_forest.predict(X_test)\n","\n","random_forest.score(X_train, y_train)\n","acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n","print(round(acc_random_forest,2,), \"%\")"]},{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"97b22da6-7fdd-4abb-8df6-f11deba405a1","_uuid":"4a28af6cbb1041fe234a6641d49c00d60fe9f5f0","trusted":true},"outputs":[],"source":["# Logistic Regression\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","\n","Y_pred = logreg.predict(X_test)\n","\n","acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n","print(round(acc_log,2,), \"%\")"]},{"cell_type":"code","execution_count":21,"metadata":{"_cell_guid":"8d26f82f-2621-4f24-883e-8ea067759f94","_uuid":"015d0834932cb68d9f4062059fe97b3d0538cf28","trusted":true},"outputs":[],"source":["# KNN\n","knn = KNeighborsClassifier(n_neighbors = 3)\n","knn.fit(X_train, y_train)\n","\n","Y_pred = knn.predict(X_test)\n","\n","acc_knn = round(knn.score(X_train, y_train) * 100, 2)\n","print(round(acc_knn,2,), \"%\")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"77b27b3f-1669-47c8-9df9-756f79bc96a9","_uuid":"68ede73124edd6cfa80fe215061c8d74ac125ed8"},"source":["## Machine Learning Discussion\n","Our simple model is only able to classify people with a 24% of right guesses, which is not too much. \n","\n","Now we will perform machine learning with the introverted/extroverted column, and we'll see if our model is able to classify if someone is introverted or extroverted with a higher precision. So let's take a deeper dive into our model to get a better perspective on our predicting. Because this isn't going to be high enough quality to be helpful for anyone. :("]},{"cell_type":"code","execution_count":24,"metadata":{"_cell_guid":"5fc456c1-0cb5-4a21-94ff-1b124e3198a6","_uuid":"4ba8140f5e08778e0ab69fa000459a171c068d76","trusted":true},"outputs":[],"source":["XX = df.drop(['type','posts','I-E'], axis=1).values\n","yy = df['I-E'].values\n","\n","print(\"outcome shape\",yy.shape)\n","print(\"input shape for machine learning data\",XX.shape)\n","\n","XX_train,XX_test,yy_train,yy_test=train_test_split(XX,yy,test_size = 0.1, random_state=5)\n","\n","sgdd = SGDClassifier(max_iter=5, tol=None)\n","sgdd.fit(XX_train, yy_train)\n","Y_predd = sgdd.predict(XX_test)\n","sgdd.score(XX_train, yy_train)\n","acc_sgdd = round(sgdd.score(XX_train, yy_train) * 100, 2)\n","print(round(acc_sgdd,2,), \"%\")"]},{"cell_type":"code","execution_count":29,"metadata":{"_cell_guid":"4a3c291d-f595-4960-9f5e-9a540d8b98a2","_uuid":"a5dc51c11b33647a4eaa5fb23a50fe3068d2715a","trusted":true},"outputs":[],"source":["random_forestt = RandomForestClassifier(n_estimators=100)\n","random_forestt.fit(XX_train, yy_train)\n","\n","Y_predictionn = random_forestt.predict(XX_test)\n","\n","random_forestt.score(XX_train, yy_train)\n","acc_random_forestt = round(random_forestt.score(XX_train, yy_train) * 100, 2)\n","print(\"Random Forest Predictions Model\",round(acc_random_forestt,2,), \"%\")"]},{"cell_type":"code","execution_count":31,"metadata":{"_cell_guid":"d2d3c376-cc90-468b-9f5d-65a5262dddb7","_uuid":"d016e4899884bd7df54f8a008ef16147828fcbae","trusted":true},"outputs":[],"source":["# Logistic Regression\n","logregg = LogisticRegression()\n","logregg.fit(XX_train, yy_train)\n","\n","Y_predd = logregg.predict(XX_test)\n","\n","acc_logg = round(logregg.score(XX_train, yy_train) * 100, 2)\n","print(\"Logisitic Regression Prediction Accuracy\",round(acc_logg,2,), \"%\")"]},{"cell_type":"code","execution_count":32,"metadata":{"_cell_guid":"bf4145c0-54d1-4706-b436-d38689791caf","_uuid":"adf9af8db8ec105cc00273b0b494fc0f70d0f811","trusted":true},"outputs":[],"source":["# KNN\n","knnn = KNeighborsClassifier(n_neighbors = 3)\n","knnn.fit(XX_train, yy_train)\n","\n","Y_predd = knnn.predict(XX_test)\n","\n","acc_knnn = round(knnn.score(XX_train, yy_train) * 100, 2)\n","print(\"Knn neighbor prediction value\",round(acc_knnn,2,), \"%\")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"9375705f-79f3-4cb1-8d5a-16db200da250","_uuid":"4fc8d8f3cef8422c708cd10da7b38762ab729c01"},"source":["# Random Forest Prediction\n","\n","Random Forest Prediction - 100 %\n","Logistic Regression Prediction - 77.1 %\n","Knn neighbor prediction model - 83.66 %\n","\n","So we see our model has an accuracy of 77%, not bad for such a simple model! Let's see what else we can do!"]},{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"f5feb407-e16a-4bfd-ab8c-90426336d3b8","_uuid":"780fd3061b547a9c370c978648fde337bf47b332","trusted":true},"outputs":[],"source":["new_column=[]\n","for z in range(len(df['posts'])):\n","    prov=df['posts'][z]\n","    prov2= re.sub(r'[“€â.|,?!)(1234567890:/-]', '', prov)\n","    prov3 = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', prov)\n","    prov4 = re.sub(r'[|||)(?.,:1234567890!]',' ',prov3)\n","    prov5 = re.sub(' +',' ', prov4)\n","    prov6 = prov5.split(\" \")\n","    counter = Counter(prov6)\n","    counter2 = counter.most_common(1)[0][0]\n","    new_column.append(counter2)\n","df['most_used_word'] = new_column\n","print(df.head())\n","print(df['most_used_word'].unique())"]},{"cell_type":"markdown","metadata":{"_uuid":"56d0ec682b4d393e32f9a328ed57fa108c1d65bb"},"source":["Conclusion\n","\n","We have identified and outline the key personality traits of different types of people. The biggest takeaways is that personality type does not predict success or future results. What it does predict is your strengths and weaknesses in terms of personality. And one of the things I have taken into consideration is that when we are creating teams to fight crime, develop amazing software, or simple play sports. It's important to consider everyone technical position on the team, but it's also deeply important to explore to soft skills to ensure strengths and weakness are balanced. Which allows another layer of interdisciplinary not only in technicall skill set, but also in mindset and personality. In short, this is just the first step into creating a personality type model based on meyers briggs assessment from social media comment data. The next step is to focus in one close domain use cases to solve real problems. \n","![Personality](https://bj1oh303t6x351kzp35xea4o-wpengine.netdna-ssl.com/wp-content/uploads/2014/08/mbti-dating-infographic-section1.gif)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fc6497098f378400f5b048a5b2e910a03ebddbe0","collapsed":true,"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}
